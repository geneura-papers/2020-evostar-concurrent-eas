\documentclass[runningheads]{llncs} % -*- mode: LaTeX -*- 
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Testing the intermediate disturbance hypothesis in concurrent evolutionary algorithms.}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{JJ Merelo\inst{1}\orcidID{0000-1111-2222-3333} \and
  Mario García Valdez\inst{2}\orcidID{1111-2222-3333-4444}}
%
\authorrunning{JJ Merelo et al.}
\institute{Universidad de Granada, Granada, Spain\\
  \email{jmerelo@ugr.es}\\
  \and
Instituto Tecnológico de Tijuana, Tijuana, Baja California, México\\
\email{mario@tectijuana.edu.mx}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Concurrency is a powerful abstraction that can be used to model and
implement multi-deme evolutionary algorithms, but it breaks open many degrees of
freedom, one of which is what the different populations in different
threads can do and how they interact (via a combination of populations)
with each other. One of them is synchrony: although threads can run
asynchronously, they often perform the same amount of work, which
brings them to a (rough) synchrony. Our intention in this paper is to
test if the intermediate disturbance hypothesis holds: this kind of
synchrony is a small disturbance, which together with a big
disturbance will not boost diversity; however, moderate
disturbances will. We will test different ways of creating 
this intermediate disturbance by changing how different threads
operate or altering its working it in some other ways.

\keywords{Intermediate disturbance hypothesis  \and evolutionary algorithms \and Concurrency \and Distributed algorithms.}
\end{abstract}

\section{Introduction}

The intermediate disturbance hypothesis was introduced by several researchers in
the seventies \cite{connell1978diversity} to explain the diversity
found in different ecosystems, and it states \cite{reece2014campbell}
that
\begin{quote}
  ... Moderate levels of disturbance foster greater species diver-
sity than do low or high levels of disturbance
\end{quote}

% Side Idea: I was watching a video on Evolutionary Biology  where the hypothesis for
% really different species (diversity) was more tied to a minority of individuals 
% that broke the mold and move to other terretories for instance.
% Those changes had more impact than the chromosome or DNA information 
% that was passed to siblings - Mario
% Gabi gave me the link: https://www.youtube.com/watch?v=V-hwPkphk-0
% Good catch, but I would need a reference for that - JJ

These levels refer to amplitude as well as frequency; a disturbance
happening too often will wipe out all diversity, if it happens rarely
the system reaches equilibrium bringing species that have
some competitive advantage, therefore, dominating the ecosystem; in the same way,
a high level of disturbance like temperatures that change a lot will
not allow species to thrive except those that can stand them, a
moderate temperature range across day and night will allow a whole lot
of adapted species to survive together, in the same way as it happens in
the rainforest. This disturbance may also refer to changes in the genetic pool brought by the introduction of new populations. % Add this to refer to new populations

This optimal diversity is something that is sought in evolutionary algorithms, since diversity makes them avoid falling in local optima, especially in multi-deme
distributed or concurrent evolutionary algorithms, where {\em
  disturbances} will usually take the form of changes in the
population, usually selection or insertion policies; as a matter of  
% Distributed is not always mult-population, for instance
% distributed fitness Evaluation. 
% The focus of the work is clear, so I don't know if there is a
% need to explain this.  - Mario
% I just added multi-deme - JJ
fact, we investigated this kind of hypothesis in \cite{jj:2008:PPSN},
finding that, effectively, making populations evolve asynchronously so
that they, by being in a different state of evolution, can result in
an {\em intermediate} disturbance by interchanging members of the
population, can result in a boost to the performance of an algorithm,
offering better results than synchronously evolving populations or
other setups with a lesser degree of disturbances.

Concurrent evolutionary algorithms are placed at a different level of
abstraction than distributed algorithms; they can be run in parallel
or not, distributed over many computers or simply many processors, but
they use high-level language constructs such as channels, tasks and
messages that ensure that there are no deadlocks and every task runs
smoothly until it's finished. Languages such as Raku (formerly known
as Perl 6) \cite{lenzperl}, include channels as part of the
fundamental data structures, and using them, we can implement
concurrent evolutionary algorithm following Hoare's Communicating
Sequential Processes model \cite{Hoare:1978:CSP:359576.359585}.

In this kind of evolutionary algorithms
\cite{Merelo:2018:MEA:3205651.3208317,DBLP:conf/evoW/GuervosLCVG19,merelo2019scaling,10.1007/978-3-030-00350-0_2}
there is no {\em migration} {\em per se}, although populations are not
moved from one {\em island} to another, but {\em merged}, the
intermediate disturbance principle should apply; we should {\em let
  nature be our guide} \cite{Zen} and apply it to achieve a certain 
level of performance, scaling or both.

However, there's no way to introduce those intermediate disturbances
from first principles, and in such a way that it does not really % what "first principles" are? - Mario
change the nature of the algorithm in fundamental ways. For starters,
in several occasions this intermediate disturbance effect just happens % quotes ? 
in asynchronous evolutionary algorithms
\cite{DBLP:journals/corr/GuervosG15}, so we would be trying to add
intermediate disturbances to something that is already intermediately
disturbed, creating too much disturbance indeed. Second, the only way
we have to actually find out that it works is by observing its effects
and discarding other possible causes; in a word, we will be trying to
heuristically measure the effects of different types of disturbances on the population, % can we enumerate a few? - Mario
which can only be made by changing the degree of evolution a population undergoes in every task; we will do that via alterations in the number of generations or in the population. This way, and heuristically, we will pick the one that has the more positive effect in algorithmic,
performance terms, or both. % What is the relationship between disturbances and diversity? - Mario
% is diversity justa a type of disturbance? - Mario
What we expect via these changes in the degree of evolution of different populations is to create a disturbance, possibly of moderate size, when these populations mix. We will observe if this disturbance has the right size by observing its effects on the performance of the algorithm; higher diversity will mean better performance. We will check how this performance boost works when we scale from two to eight or ten simultaneous tasks.

The rest of the paper is organized as follows. Next, we will present
the state of the art in the use or observation of the intermediate
disturbance hypothesis in bioinspired algorithms; next we will
describe the experimental setup for this paper. Section \ref{sec:res}
will present the results, followed by a section with discussions and
future lines of work that will close the paper.

\section{State of the art}

The intermediate disturbance hypothesis
\cite{connell1978diversity,grime1973competitive} has not really had a long
run in the area of bioinspired algorithms; using % One "as a matter of fact" is ok. But two? - Mario
{\em big} disturbances such as hypermutation has been more popular than
that. This technique was popularized by another bioinspired
methodology, immune systems, \cite{jansen2011analyzing}, it has been
used under many different names such as the {\em plague} methodology
that was proposed for genetic programming
\cite{fernandez2003effect}. Even as their names suggest a degree of
perturbation of the system that is beyond moderation, it is very
likely that their real effect is that of a moderate disturbance. The
{\em plague}, for instance, just removes some individuals in he
population; hypermutation does generate new (faulty) copies of some
specific individuals, generating a moderate disturbance that explains
its generation of diversity.

The same happens in the area of distributed evolutionary algorithms;
these moderate disturbances are introduced, although not really by
name. Pelta et al. \cite{pelta2006using} propose a ``cooperative
multi-thread strategy'', where every thread runs a different
optimization algorithm. The results of every thread will be a {\em
  moderate} disturbance to the solutions of the other threads, and
this is achieved explicitly by using fuzzy rules to update thread
method parameter as well as the starting point of the algorithm;
however, while this strategy avoids low disturbance, it does not
really guarantee that catastrophic high disturbance happen, making a
new solution much better than the existing ones {\em invade} the whole
system.

This is why a more explicit approach to the observation or
implementation of the intermediate disturbance hypothesis might help
to better apply it to distributed evolutionary algorithms. As such, it
has been used with a certain frequency by evolutionary algorithms,
although mainly in the area of particle swarm optimization. Gao et
al. \cite{gao2013particle} mention a {\em moderate disturbance
  strategy}, which adds exploration to the PSO algorithm; this {\em
  moderate} disturbance has the effect of increasing exploration and
thus diversity, at least in a local scale; that is also the intention
of the {\em intermediate disturbance} PSO proposed by He et
al. \cite{he2019particle}, which perturbs the position of particles
using the value initially proposed by Gao et al.

However, in the context of distributed evolutionary algorithms, it was
introduced explicitly by us in the above mentioned paper,
\cite{jj:2008:PPSN}, although we focused more in the algorithmic
effects than in the real time-wise performance, since the
implementation was not actually parallel. In that case we compared
populations operating synchronously with others that operated
asynchronously by starting at different points in time; this simple
procedure had the effect of a decrease in the number of evaluations
needed. A different implementation of the same concept was made in
that we called a {\em multikulti} algorithm
\cite{Araujo2010}, which used an explicitly parallel
  population. This created the intermediate disturbance by using
  genotypic differences to select migrants from one island (in an
  island-bsed GA) to another; in this paper, the moderate perturbation
  created by this inflow of population was explicitly proved to
  increase diversity, and then performance.

In this paper we will try to take the state of the art a bit further
by first, testing the hypothesis in a concurrent environment, trying
to create different conditions that produce a moderate disturbance,
and measuring its algorithmic as well as performance effects. We'll
describe the setup next.

\section{Experimental setup}

The overall architecture of the algorithm used in this paper was
presented in \cite{DBLP:conf/evoW/GuervosLCVG19}. Essentially, it's a
concurrent evolutionary algorithm written in Raku that uses channels
for interchange of information among different tasks.

There are two kind of tasks:\begin{itemize}
  
\item The evolutionary tasks run a classical evolutionary algorithm
  for a number of generations with a fixed population. This is the
  task that we will scale. 
\item The mixer task will be used to interchange information among
  tasks; it will pick up population probability vectors in pairs from
  the ``mixer'' channel, create a new probability vector crossing over the
  probabilities of them. This, together with a random member of the
  initial pair, will be sent back to the ``evolutionary'' channel.
\end{itemize}

\begin{figure}[h!tb]
\includegraphics[width=0.95\columnwidth]{imgs/comma-4-threads.png}
\caption{Monitor showing the working of the baseline concurrent evolutionary
  algorithm with 4 threads, as shown by the Comma IDE concurrency monitor.}
\label{fig:comma}
%
\end{figure}
%
The data flow is as follows.\begin{itemize}
\item A set of probability distribution vectors are initially
  generated. These will be the per-gene probabilities used to generate
  the initial populations. We will generate 1 or 2 sets of
  probabilities more than the number of (evolutionary) threads; for
  instance, 12 vectors for 10 evolutionary threads.
\item These sets are sent to the mixer thread, that mixes and sends
  them to the evoluitonary channel.
\item The evolutionary tasks pick up one probability vector, rebuild
  the population using it, and run an evolutionary algorithm for a
  fixed number of generations or until solution is found. If that's
  not the case, 1/4 of the population with best fitness will be used
  to generate a probability vector, sent back to the mixer channel.
\item Each task is event driven, and ``wakes up'' when there's a
  vector available in the channel; it's implemented as a promise that
  will be fulfilled when the solution is found in that specific
  thread. 
\end{itemize}


The timeline of this concurrent algorithm is shown in Figure
\ref{fig:comma}; this monitor shows tasks as bars, and specific events
as triangles. The mixer task can be barely appreciated, since it takes
a very short time, but you can observe it 's always running in a
single thread and it starts before the others. Since generation (and
mixer) start concurrently with evolution, new threads {\em wake up} as
new information is available in the channel; they end at different
points in the timeline, but their state of evolution should be
approximately the same, since they have been submitted to the same
number of evaluations and the population is the same. Please observe
also that there are few gaps (except at the beginning) and that
concurrency is use quite efficiently throughout all the run.

In the next section we will subject this baseline operation to
different kind of perturbations, looking for that goldilocks zone
where perturbations are moderate and maximum diversity emerges.



\section{Acknowledgements}

We are grateful to Jonathan Worthington and the rest of the Edument team for their disposition to help with implementation problems and provide suggestions to make this work correctly. This is extended to the rest of the Raku development team, which is an excellent and technically knowledgeable community committed to creating a great language. This paper has been supported in part by projects DeepBio (TIN2017-85727-C4-2-P).

\bibliographystyle{splncs04}
\bibliography{geneura,concurrent,GA-general,perl6}

\end{document}
